{"cells":[{"cell_type":"markdown","source":["# License"],"metadata":{"id":"Ft47XpDRpLtI"},"id":"Ft47XpDRpLtI"},{"cell_type":"code","execution_count":null,"id":"5c86ed4a-737f-4d87-9cbc-39ea17f8b5dd","metadata":{"pycharm":{"name":"#%% md\n"},"id":"5c86ed4a-737f-4d87-9cbc-39ea17f8b5dd"},"outputs":[],"source":["# Copyright 2021 University of San Andres' Authors."]},{"cell_type":"code","execution_count":null,"id":"28f6a298","metadata":{"pycharm":{"name":"#%%\n"},"id":"28f6a298"},"outputs":[],"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"code","execution_count":null,"id":"2a54e634","metadata":{"pycharm":{"name":"#%%\n"},"id":"2a54e634"},"outputs":[],"source":["#@title MIT License\n","#\n","# Copyright (c) 2021 University of San Andres\n","#\n","# Permission is hereby granted, free of charge, to any person obtaining a\n","# copy of this software and associated documentation files (the \"Software\"),\n","# to deal in the Software without restriction, including without limitation\n","# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n","# and/or sell copies of the Software, and to permit persons to whom the\n","# Software is furnished to do so, subject to the following conditions:\n","#\n","# The above copyright notice and this permission notice shall be included in\n","# all copies or substantial portions of the Software.\n","#\n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n","# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n","# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n","# DEALINGS IN THE SOFTWARE."]},{"cell_type":"markdown","id":"4df65c74","metadata":{"pycharm":{"name":"#%% md\n"},"id":"4df65c74"},"source":["# Entrená tu primer red neuronal: clasificación MNIST\n","\n","En esta primera instancia, vamos a declarar o importar las dependencias que necesitamos para comenzar a trabajar con el tutorial.\n","\n","A través de las palabras reservadas de Python3, como por ejemplo `import`, inicializaremos los siguientes paquetes."]},{"cell_type":"code","execution_count":null,"id":"97d007b5","metadata":{"pycharm":{"name":"#%%\n"},"id":"97d007b5"},"outputs":[],"source":["%load_ext tensorboard\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)"]},{"cell_type":"markdown","source":["Luego, verificamos que tengamos correctamente instalada la placa de video, o mejor dicho, la *Graphical Processing Unit* (*GPU*)."],"metadata":{"id":"TpatKUfi39Qh"},"id":"TpatKUfi39Qh"},{"cell_type":"code","execution_count":null,"id":"33ee05e8-f264-44a3-9817-8d66d134487b","metadata":{"pycharm":{"name":"#%%\n"},"id":"33ee05e8-f264-44a3-9817-8d66d134487b"},"outputs":[],"source":["gpu_devices = tf.config.list_physical_devices('GPU')\n","for device in gpu_devices:\n","    tf.config.experimental.set_memory_growth(device, True)\n","\n","print('Num GPU available:', len(gpu_devices))"]},{"cell_type":"markdown","id":"202ebcb7","metadata":{"pycharm":{"name":"#%% md\n"},"tags":[],"id":"202ebcb7"},"source":["## Descargá el set de datos MNIST"]},{"cell_type":"markdown","id":"bfb0cee7","metadata":{"pycharm":{"name":"#%% md\n"},"id":"bfb0cee7"},"source":["Este tutorial usa el conjunto de datos más famoso conocido como [MNIST](http://yann.lecun.com/exdb/mnist). Éste contiene 60.000 imágenes de números a mano alzada, en escala de grises, y un conjunto de datos de prueba de 10.000 ejemplos. Cada imagen son de baja resolución (28x28 pixels) como se ve aquí:\n","\n","<table>\n","  <tr><td align=\"center\">\n","    <img src=\"https://neurohive.io/wp-content/uploads/2019/05/Screenshot-from-2019-05-29-21-23-47.png\"\n","         alt=\"MNIST Sprite\" width=\"1024\">\n","  </td></tr>\n","  <tr><td align=\"center\">\n","    <b>Figura 1.</b> <a href=\"http://yann.lecun.com/exdb/mnist\">Muestras MNIST</a><br/>&nbsp;\n","  </td></tr>\n","</table>\n","\n","MNIST es un conjunto de datos utilizado como el \"Hola, Mundo!\" de Machine Learning para Visión por Computadoras. MNIST contiene imágenes a mano alzada desde el 0 al 9 de baja resolución.\n","\n","Existen otro tipo de conjunto de datos basados en este llamado [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), los cuales funcionan como punta pie inicial para verificar que el desarrollo de algoritmos funcionan. Sirven generalemente para hacer pruebas y refinamiento de los algoritmos en cuestión. \n","\n","Utilizaremos 60.000 imágenes para entrenar una red neuronal y 10.000 imágenes para analizar la exactitud de la red para clasificar cada una de las imágenes. Se utilizará TensorFlow para acceder directamente al conjunto de datos de manera muy práctica."]},{"cell_type":"code","execution_count":null,"id":"8036b0e2","metadata":{"pycharm":{"name":"#%%\n"},"id":"8036b0e2"},"outputs":[],"source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"]},{"cell_type":"markdown","id":"a4f7b594-7e53-42a3-a335-2c3cdfa970d9","metadata":{"pycharm":{"name":"#%% md\n"},"id":"a4f7b594-7e53-42a3-a335-2c3cdfa970d9"},"source":["## Inspección de los datos"]},{"cell_type":"markdown","id":"97d5cc8f-94f0-48dc-b507-3f4b2bbbf0dd","metadata":{"pycharm":{"name":"#%% md\n"},"id":"97d5cc8f-94f0-48dc-b507-3f4b2bbbf0dd"},"source":["A través de la API de Tensorflow pudimos obtener las imágenes de entrenamiento y prueba. \n","\n","En esta ocasión, vamos a inspeccionar las primeras 10 etiquetas asociadas a las primeras 10 imágenes en el conjunto de entrenamiento."]},{"cell_type":"code","execution_count":null,"id":"669afda6","metadata":{"pycharm":{"name":"#%%\n"},"id":"669afda6"},"outputs":[],"source":["train_labels[:10]"]},{"cell_type":"markdown","id":"a4e222f9-6969-4071-bcd6-1f956d59b449","metadata":{"pycharm":{"name":"#%% md\n"},"id":"a4e222f9-6969-4071-bcd6-1f956d59b449"},"source":["A continuación, definimos una lista con los nombres de las clases/etiqueta en formato `string` para visualizar un poco mejor las imágenes."]},{"cell_type":"code","execution_count":null,"id":"044ff1fa","metadata":{"pycharm":{"name":"#%%\n"},"id":"044ff1fa"},"outputs":[],"source":["class_names = [\n","    'Zero', 'One', 'Two',\n","    'Three', 'Four', 'Five',\n","    'Six', 'Seven', 'Eight',\n","    'Nine'\n","]"]},{"cell_type":"markdown","id":"92cf01e3-4252-4c70-85fa-0abf8a079bd7","metadata":{"pycharm":{"name":"#%% md\n"},"id":"92cf01e3-4252-4c70-85fa-0abf8a079bd7"},"source":["Uno de los primeros pasos es revisar que los datos se encuentren correctamente cargados. Por eso, en pasos anteriores revisamos algunas etiquetas del conjunto de entrenamiento. \n","\n","Ahora corroboraremos el tamaño de ambos conjuntos de datos. Habíamos dicho que serían 60.000 imágenes de entrenamiento y 10.000 de prueba.\n","\n","Por último, mostraremos una de las imágenes de forma más visual con la biblioteca que importamos más arriba llamada `matplotlib`."]},{"cell_type":"code","execution_count":null,"id":"dd5ca663-4558-4a29-a524-549a3e05cfc8","metadata":{"pycharm":{"name":"#%%\n"},"id":"dd5ca663-4558-4a29-a524-549a3e05cfc8"},"outputs":[],"source":["train_images.shape[0]"]},{"cell_type":"code","execution_count":null,"id":"9f248b67-4c1c-49d5-9b90-5cde16adc28a","metadata":{"pycharm":{"name":"#%%\n"},"id":"9f248b67-4c1c-49d5-9b90-5cde16adc28a"},"outputs":[],"source":["test_images.shape[0]"]},{"cell_type":"markdown","id":"8d56eaac-d590-4187-93cd-8141ba5618d5","metadata":{"pycharm":{"name":"#%% md\n"},"id":"8d56eaac-d590-4187-93cd-8141ba5618d5"},"source":["Observamos que cada uno de los pixels de la imagen puede tener un valor entre 0 y 255. Un paso previo para preparar los datos es aplicar una técnica denominada _normalización_. Es decir, haremos que los valores de los pixels estén entre 0 y 1 únicamente."]},{"cell_type":"code","execution_count":null,"id":"0696ec91","metadata":{"pycharm":{"name":"#%%\n"},"id":"0696ec91"},"outputs":[],"source":["plt.figure()\n","plt.imshow(train_images[0], cmap=plt.cm.binary)\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"markdown","id":"c22e98cd-7b84-4d52-b670-4a0a027a36f7","metadata":{"pycharm":{"name":"#%% md\n"},"id":"c22e98cd-7b84-4d52-b670-4a0a027a36f7"},"source":["La normalización la realizamos en ambos conjuntos de datos dividiendo las listas por 255."]},{"cell_type":"code","execution_count":null,"id":"20156899","metadata":{"pycharm":{"name":"#%%\n"},"id":"20156899"},"outputs":[],"source":["train_images = train_images / 255.0\n","test_images = test_images / 255.0\n","\n","plt.figure()\n","plt.imshow(train_images[0], cmap=plt.cm.binary)\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"markdown","id":"64a88a1b-47a9-40cc-a053-13fbdd320a2f","metadata":{"pycharm":{"name":"#%% md\n"},"id":"64a88a1b-47a9-40cc-a053-13fbdd320a2f"},"source":["A partir de lo anterior, mostramos 25 imágenes de entrenamiento con sus respectivas etiquetas."]},{"cell_type":"code","execution_count":null,"id":"f77540a4","metadata":{"pycharm":{"name":"#%%\n"},"id":"f77540a4"},"outputs":[],"source":["plt.figure(figsize=(10,10))\n","for i in range(25):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i], cmap=plt.cm.binary)\n","    plt.xlabel(class_names[train_labels[i]])\n","plt.show()"]},{"cell_type":"markdown","id":"517132c6-c4ed-401c-9c9b-20561a70bef6","metadata":{"pycharm":{"name":"#%% md\n"},"id":"517132c6-c4ed-401c-9c9b-20561a70bef6"},"source":["## Arquitectura de la red neuronal"]},{"cell_type":"markdown","id":"1ba5fc97-88cb-400e-8499-cb48395795b0","metadata":{"pycharm":{"name":"#%% md\n"},"id":"1ba5fc97-88cb-400e-8499-cb48395795b0"},"source":["Lo siguiente es definir el modelo que nos permitirá entrenarlo y luego clasificar una nueva imagen automáticamente. Para ello se definen las capas de la red neuronal, cada una de las cuáles cumplen un rol muy importante en la construcción del modelo.\n","\n","En primer lugar, definimos la capa `Flatten` que permitirá convertir una imagen de 28x28 en un vector o lista de longitud 768. Esta capa luego se conecta con una segunda capa denominada `Dense`, equivalente a una capa donde todas sus neuronas se conectan con la anterior y con la siguiente. Por último, definimos una segunda capa `Dense` con la diferencia que la función de activación en la primera es una \"Función ReLU\", y la segunda una \"Función Softmax\"."]},{"cell_type":"code","execution_count":null,"id":"05aaf480-6562-46c7-82ea-19234573e600","metadata":{"pycharm":{"name":"#%%\n"},"id":"05aaf480-6562-46c7-82ea-19234573e600"},"outputs":[],"source":["# Choose the right number of neurons\n","neurons_number = 1\n","\n","model = keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(28, 28)),\n","    tf.keras.layers.Dense(neurons_number, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])"]},{"cell_type":"code","execution_count":null,"id":"5977cbc4-7625-4460-9ea1-e3b363fad0ad","metadata":{"pycharm":{"name":"#%%\n"},"id":"5977cbc4-7625-4460-9ea1-e3b363fad0ad"},"outputs":[],"source":["print(model.summary())"]},{"cell_type":"markdown","id":"b082eea5-2686-4653-8ea1-7709843237c7","metadata":{"pycharm":{"name":"#%% md\n"},"id":"b082eea5-2686-4653-8ea1-7709843237c7"},"source":["Por útlimo, queremos definir ciertos parámetros importante a la hora de cómo se entrena una red neuronal. Éstos son el tipo de optimizador, la función de error o _loss_, y las métricas de interés.\n","\n","Respecto a las métricas, sólo hablaremos de la _accuracy_ o exactitud en este tutorial."]},{"cell_type":"code","execution_count":null,"id":"a82f833c","metadata":{"pycharm":{"name":"#%%\n"},"tags":[],"id":"a82f833c"},"outputs":[],"source":["# Choose your learning rate!\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1), \n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","id":"8f74ac2c-7358-48ee-aedb-5794c1ac944d","metadata":{"pycharm":{"name":"#%% md\n"},"id":"8f74ac2c-7358-48ee-aedb-5794c1ac944d"},"source":["## Entrenamiento\n","\n","¡Ahora a entrenar!"]},{"cell_type":"code","execution_count":null,"id":"e195140e-55b7-4dd2-b5d7-7ffcc747fe8a","metadata":{"id":"e195140e-55b7-4dd2-b5d7-7ffcc747fe8a"},"outputs":[],"source":["import os\n","import datetime\n","\n","basedir = '/tmp/mnist/'\n","logdir = os.path.join(basedir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","os.makedirs(logdir, exist_ok=True)\n","\n","%tensorboard --reload_multifile True --logdir {basedir}"]},{"cell_type":"code","source":["# Choose the right number of epochs too.\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","\n","model.fit(train_images, train_labels, epochs=1, callbacks=[tensorboard_callback])"],"metadata":{"id":"AJ6tQ-6jQWH8"},"id":"AJ6tQ-6jQWH8","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"3701ce45","metadata":{"pycharm":{"name":"#%%\n"},"id":"3701ce45"},"outputs":[],"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","\n","print('Test accuracy:', test_acc)"]},{"cell_type":"markdown","id":"b29ffb5f-9b8c-4147-b02a-4eb20bb42c81","metadata":{"pycharm":{"name":"#%% md\n"},"id":"b29ffb5f-9b8c-4147-b02a-4eb20bb42c81"},"source":["## Predicción"]},{"cell_type":"markdown","id":"a5521d77-8e00-4251-9e4e-386ab9a4ba3a","metadata":{"pycharm":{"name":"#%% md\n"},"id":"a5521d77-8e00-4251-9e4e-386ab9a4ba3a"},"source":["Luego del entrenamiento, viene la etapa de la _predicción_. \n","\n","A partir de las imágenes de prueba, computaremos las predicciones de cada una de ellas con la función `predict()` de `model`. Le pasaremos la lista de imágenes, y obtendremos las predicciones."]},{"cell_type":"code","execution_count":null,"id":"d6570d4b","metadata":{"pycharm":{"name":"#%%\n"},"id":"d6570d4b"},"outputs":[],"source":["predictions = model.predict(test_images)"]},{"cell_type":"markdown","id":"cb00c89f-e96f-487c-8e6d-0e547fa9c6a7","metadata":{"pycharm":{"name":"#%% md\n"},"id":"cb00c89f-e96f-487c-8e6d-0e547fa9c6a7"},"source":["Las predicciones no dicen directamente cuál es la etiqueta o clase que le corresponde a la imagen. Las predicciones son los valores que la capa de neuronas de salida entrega. Cada una de las neuronas de salida, que tienen que ser la misma cantidad de neuronas que de etiquetas, dirá **cúal es la probabilidad de que la imagen en cuestión sea de la clase a la que la neurona corresponde**. Estos valores en la jerga de inteligencia artificial se denominan _logits_ en problemas de clasificación."]},{"cell_type":"code","execution_count":null,"id":"320dc9da","metadata":{"pycharm":{"name":"#%%\n"},"id":"320dc9da"},"outputs":[],"source":["predictions[0]"]},{"cell_type":"markdown","id":"42b542a8-8793-444c-a28b-a54befab1794","metadata":{"pycharm":{"name":"#%% md\n"},"id":"42b542a8-8793-444c-a28b-a54befab1794"},"source":["Aquí pueden ver las predicciones de la red neuronal respecto a la primer imagen de prueba.\n","\n","Se puede ver que la salida es un vector de 10 posiciones, desde el 0 al 9, donde cada posición corresponde a una etiqueta. Es decir, la posición 3 del vector corresponde a la clase o etiqueta \"Three\"."]},{"cell_type":"markdown","id":"d7c28d08-05f3-43cd-b937-c31b23bc2aa1","metadata":{"pycharm":{"name":"#%% md\n"},"id":"d7c28d08-05f3-43cd-b937-c31b23bc2aa1"},"source":["Finalmente, en los problemas de clasificación se utiliza una función que determina cuál es la clase a la que la entrada corresponde. En este caso, la entrada es la imágen y la salida va a ser la clase o el número que la red indentificó. \n","\n","Para extraer esto, es necesario llamar a una función denominada `argmax` de la biblioteca `numpy`."]},{"cell_type":"code","execution_count":null,"id":"94203774","metadata":{"pycharm":{"name":"#%%\n"},"id":"94203774"},"outputs":[],"source":["np.argmax(predictions[0])"]},{"cell_type":"markdown","id":"ee5f9bee-53e5-4fa2-9a35-e102ec1c9b72","metadata":{"pycharm":{"name":"#%% md\n"},"id":"ee5f9bee-53e5-4fa2-9a35-e102ec1c9b72"},"source":["Bien, hasta el momento hemos computado o inferido las etiquetas de cada una de las imágenes de prueba que la red neuronal NUNCA antes había visto.\n","\n","El paso siguiente es verificar que la red está en lo correcto, o más específicamente, cuán en lo correcto se encuentra. Es por eso que tenemos las etiquetas asociadas al conjunto de datos de prueba. \n","\n","Observemos la etiqueta de prueba de la primer imagen."]},{"cell_type":"code","execution_count":null,"id":"faa81743","metadata":{"pycharm":{"name":"#%%\n"},"id":"faa81743"},"outputs":[],"source":["test_labels[0]"]},{"cell_type":"code","execution_count":null,"id":"7675f484","metadata":{"pycharm":{"name":"#%%\n"},"id":"7675f484"},"outputs":[],"source":["# No modificar este código\n","\n","def plot_image(i, predictions_array, true_label, img):\n","  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  \n","  plt.imshow(img, cmap=plt.cm.binary)\n","\n","  predicted_label = np.argmax(predictions_array)\n","  if predicted_label == true_label:\n","    color = 'blue'\n","  else:\n","    color = 'red'\n","  \n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n","\n","def plot_value_array(i, predictions_array, true_label):\n","  predictions_array, true_label = predictions_array[i], true_label[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n","  plt.ylim([0, 1]) \n","  predicted_label = np.argmax(predictions_array)\n"," \n","  thisplot[predicted_label].set_color('red')\n","  thisplot[true_label].set_color('blue')"]},{"cell_type":"code","execution_count":null,"id":"10109c4d","metadata":{"pycharm":{"name":"#%%\n"},"id":"10109c4d"},"outputs":[],"source":["i = 0\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(i, predictions, test_labels, test_images)\n","plt.subplot(1,2,2)\n","plot_value_array(i, predictions,  test_labels)\n","plt.xticks(range(10), class_names, rotation=45)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"46ad3d20","metadata":{"pycharm":{"name":"#%%\n"},"id":"46ad3d20"},"outputs":[],"source":["i = 12\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(i, predictions, test_labels, test_images)\n","plt.subplot(1,2,2)\n","plot_value_array(i, predictions,  test_labels)\n","plt.xticks(range(10), class_names, rotation=45)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"7155d509","metadata":{"pycharm":{"name":"#%%\n"},"id":"7155d509"},"outputs":[],"source":["# Graficar las primeras X imágenes de prueba, su predicción, y la verdadera etiqueta. \n","# Predicciones correctas en azul, incorrectas en rojo.\n","num_rows = 5\n","num_cols = 3\n","num_images = num_rows*num_cols\n","plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n","for i in range(num_images):\n","    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","    plot_image(i, predictions, test_labels, test_images)\n","    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","    plot_value_array(i, predictions, test_labels)\n","    plt.xticks(range(10), class_names, rotation=45, fontsize=8)\n","plt.show()"]}],"metadata":{"environment":{"name":"tf2-gpu.2-5.m76","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m76"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"mnist_classification.ipynb","provenance":[],"collapsed_sections":["Ft47XpDRpLtI"],"private_outputs":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}